from collections import defaultdict
from tqdm.autonotebook import trange
from algorithm_utils import *


class ImageRegistrant:
    """Image registration solver class.

    This class provides an encapsulation of the image registration procedure.
    Both global affine transformations and non-linear transformations are provided.
    The global one uses gradient descent method to learn one single linear transformation
    to transform all position of the moving image to target image.
    In practice, backward transformation is employed to perform the transformation.
    The image would be mapped to gray scale so as to accelerate and simplify calculation.

    Attributes:
    -----------
    moving_img: np.ndarray
        The float image to be deformed, should be gray scale with shape (H, W)
    fixed_img: np.ndarray
        The fixed reference image, should be gray scale with shape (H, W)
    image_coords: np.ndarray
        Coordinates of the image as an array to accelerate transformation by
        matrix multiplication, with shape (2, H, W). image_coords[:, r, c] = array([r, c])
    params: dict[float]
        Transformation parameters to be learnt, initialized as identity matrix by default. 
        Keys: "theta", "scale_x", "scale_y", "shear_x", "shear_y", "trans_x", "trans_y".
        They represent the rotation, scaling, shearing and translation effect respectively. 
        The transformation learnt is itself the backward transformation, namely from
        the coordinates of fixed image to the coordinates of moving image, but not ortherwise.
        This setting simplifies the calculation by obviating the need for matrix inversion
        to get backward transformation.
    lr: float
        The learning rate for gradient descent, can be decreased by learning rate decay.
        It is actually a common factor for all parameters. Each parameters has its own 
        learning rate controlled by `lr_ratio`
    lr_ratio: dict[float]
        For each parameter, specify a ratio to amplify/curtail its learning rate. 
        For example, the actual learning rate for translation should be larger than rotation. 
        The actual learning rate for parameter p is lr * lr_ratio[p]
    delta: dict[float]
        Specifies the difference size in gradient calculation for each parameter.
        The size of translation is larger than others'.
    losses: list[float]
        Stores the loss for each step, used for plotting.
    mid_results: list[np.ndarray]
        Stores the middle result of moved image for showing.

    Usage:
    ------
    >>> from ImageRegistrant import ImageRegistrant
    >>> reg = ImageRegistrant(moving_img, fixed_img)
    >>> reg.fit()
    >>> plt.imshow(reg.moved_img)
    """

    def __init__(self, moving_img: np.ndarray, fixed_img: np.ndarray):
        self.moving_img = normalize(moving_img)
        self.fixed_img = normalize(fixed_img)
        # get the coordinates of fixed image, indexing='ij' to swap the axis
        self.image_coords = np.stack(np.meshgrid(*map(np.arange, fixed_img.shape), indexing='ij'))
        self.losses = []
        self.mid_results = []
        self._momentum_vec = defaultdict(float)  # historical direction for momentum gradient descent

        # initialize parameters for the affine transformation
        self.params = {
            "theta": 0, "scale_x": 1, "scale_y": 1,
            "shear_x": 0, "shear_y": 0, "trans_x": 0, "trans_y": 0,
        }
        self.delta = {
            "theta": 0.01, "scale_x": 0.01, "scale_y": 0.01,
            "shear_x": 0.01, "shear_y": 0.01, "trans_x": 1, "trans_y": 1,
        }
        self.lr_ratio = {
            "theta": 1, "scale_x": 1, "scale_y": 1,
            "shear_x": 0.1, "shear_y": 0.1, "trans_x": 5e4, "trans_y": 5e4,
        }

    def _affine_transform(self):
        """Perform the global affine transformation.

        To perform the transformation specified by `self.params` on `self.image_coords`.
        `self.image_coords` is generated by `self.fixed_image`, so the transformation learnt
        is actually performed on the fixed image to do backward transformation. 
        We do not use the transformation from moving image's coordinates to fixed image's
        coordinates to escape the matrix inversion.

        Returns:
        --------
        backward_coords: np.ndarray
            The transformed coordinates. For each index(r, c) of the fixed image, 
            the value(backward_coords[:,r,c]) is the float point index on the moving image.
        """
        # used for reshape the coord matrix when doing transformation
        shape = self.image_coords.shape  

        # decompose the affine transformation to the below four components for better control
        rotation = np.array([[np.cos(self.params['theta']), np.sin(self.params['theta'])],
                             [-np.sin(self.params['theta']), np.cos(self.params['theta'])]])
        scaling = np.array([[self.params['scale_x'], 0], [0, self.params['scale_y']]])
        shearing = np.array([[1, self.params['shear_x']], [0, 1]]) @ \
                   np.array([[1, 0], [self.params['shear_y'], 1]])
        translation = np.array([self.params['trans_x'], self.params['trans_y']]).reshape(2,1)
        
        # the order the these three component can be arbitrary
        T_inv = shearing @ rotation @ scaling
        backward_coords = T_inv @ self.image_coords.reshape(shape[0], -1) + translation
        return backward_coords.reshape(shape)

    def _compute_grads(self, loss, loss_func):
        """Use finite difference method to calculate the gradient of parameters.
        
        The finite difference step is specified by `self.delta` for each parameters.
        The step for translation is larger than others in that its scale of value is larger.
        grads =~ [Loss(param+delta) - Loss(param)] / delta
        
        Args:
        -----
        loss: float
            The loss value of the moved image with fixed image calculated before.
            loss = loss_func(parameters)
        loss_func: Callable
            The loss function used in the optimization, implemented in utils and selected by users.

        Returns:
        --------
        grads: dict[float], the gradient for each parameter.
        """
        grads = {}
        for k, param in self.params.items():
            # directly and the step delta to each parameter
            self.params[k] = param + self.delta[k]
            # because the affine transformation is exerted by `self.params`
            moved_img_delta = bilinear_interp(self._affine_transform(), self.moving_img)
            loss_delta = loss_func(moved_img_delta, self.fixed_img)
            # use single sided step to reduce the calculation by half
            grads[k] = (loss_delta - loss) / self.delta[k]
            # remember to reset this parameter back
            self.params[k] = param
        return grads

    def fit(self, lr=0.2, n_step=200, momentum=0, method='mse', decay=None, save_interval=40):
        """The main training loop to perform the gradient descent.

        Use gradient descent with momentum to find the optimal transformation. 
        Momentum can accelerate the convergence and stabilize the loss.
        Learning rate decay is also implemented as a feature to adjust learning rate
        dynamically to explore more delicate structure in the loss landscape to get
        better results. Different algorithm is specified in `method` to choose the 
        loss function. Non-linear method can also be chosen by it. This optical flow 
        method is different from the linear one in that it is not learnt by gradient descent
        but solving differential equations in the image pyramid of resolutions.
        The final result is stored to `self.moved_img` for further use, so this function does
        not have return values.

        Args:
        -----
        lr: float
            The learning rate for gradient descent, can be decreased by learning rate decay.
            It is actually a common factor for all parameters. Each parameters has its own 
            learning rate controlled by `self.lr_ratio`
        n_step: int
            The total optimization step to calculate on the image.
        momentum: float
            The weight of using momentum in gradient descent method. 
            0 means do not use momentum and is equivalent to the vanilla gradient descent.
            0.9 is the popular choice for most uses.
        method: str
            To choose the method or loss function used for finding the transformation.
            Can be chosen from ["mse", "ncc", "nmi", "kl", "optical"].
            The first four are loss functions implemented to get the global linear transformation.
            They are function names to be chosen from the runtime variable `globals()`
            The last one is the non-linear optical flow method.
        decay: dict[int: float]
            Specifies when and how much to decay the learning rate. Keys are the steps to do 
            learning rate decay, and the values are the decay scale on these steps.
            Example: {30: 0.1, 60: 0.2} means at step 30 and 60, the learning rate is 
            shrunk by 0.1 and 0.2 respectively.
        save_interval: int
            The save_interval of steps to store the moved images as middle results.
        """

        # non-linear transformation method
        if method == 'optical':
            # get the relative movement vector field using optical flow
            v, u = optical_flow_tvl1(self.fixed_img, self.moving_img)
            r_coord, c_coord = self.image_coords
            # transform the moving image by the learnt movement
            self.moved_img = warp(self.moving_img, np.array([r_coord+v, c_coord+u]), mode='edge')
            return

        # get the function(Callable) by its name(str) from the runtime
        # obviates the need for writing piles of if-else to select the function
        # also adds scalability and is easy to maintain because one can always write his own
        # loss function in utils and do not need to modify code here.
        self.lr = lr
        loss_func = globals()[method]
        moved_img = None
        for step in trange(n_step):
            moved_img = bilinear_interp(self._affine_transform(), self.moving_img)
            loss = loss_func(moved_img, self.fixed_img)
            self.losses.append(loss)
            grads = self._compute_grads(loss, loss_func)
            for k, param in self.params.items():
                self._momentum_vec[k] = momentum * self._momentum_vec[k] + (1-momentum)*grads[k]
                self.params[k] = param - grads[k] * self.lr * self.lr_ratio[k]

            if step % save_interval == 0:
                self.mid_results.append(moved_img)
            if decay and step in decay:
                self.lr *= decay[step]
        self.moved_img = moved_img
        self.mid_results.append(moved_img)